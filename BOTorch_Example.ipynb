{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut_7qUec_fPS"
   },
   "source": [
    "# BOTorch tutorial\n",
    "Adapted of https://www.youtube.com/watch?v=BQ4kVn-Rt84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUHXZaZ-EBaH"
   },
   "source": [
    "First we install BOTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRylSzQ1EC0X"
   },
   "outputs": [],
   "source": [
    "!pip install botorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLB1XvRk_cp0"
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_k6vXoy_Y4p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO5iEVhA_n8i"
   },
   "source": [
    "Objective function:\n",
    "\n",
    "$e^{-(x-2)^2}+e^{-(x-6)^2/10} + \\frac{1}{x^2+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBQXY7oZ_o3S"
   },
   "outputs": [],
   "source": [
    "def target_function(individuals):\n",
    "  result = []\n",
    "  for x in individuals:\n",
    "    result.append(np.exp(-(x[0]-2)**2) + np.exp(-(x[0]-6)**2/10) + 1/(x[0]**2+1))\n",
    "  return torch.tensor(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6FwE1eYABoy"
   },
   "source": [
    "Print objective function that we want to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlqngMKbAEA6"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "x = np.linspace(-2., 10., 100)\n",
    "x_new = x.reshape((100,-1))\n",
    "z = target_function(x_new)\n",
    "\n",
    "data = go.Scatter(x=x, y=z, line_color=\"#FE73FF\")\n",
    "\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(title=\"Objective function\", xaxis_title=\"input\", yaxis_title=\"output\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3VlN1QSBIJs"
   },
   "source": [
    "Generate some data. First 10 random points from the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FzuqL7TBJSy"
   },
   "outputs": [],
   "source": [
    "train_x = torch.rand(10, 1)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSg7ptujBZkG"
   },
   "source": [
    "Then we compute the latent function $f(x)$. The true evaluation would be contaminated. $y = f(x) + \\epsilon \\quad s.t. \\quad \\epsilon \\approx N(0, \\sigma)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cI-7IyqPBOru"
   },
   "outputs": [],
   "source": [
    "exact_obj = target_function(train_x).unsqueeze(-1)\n",
    "exact_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDSXYHFFBnI-"
   },
   "source": [
    "Let us see which is the best observed value so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjNExoa9BpmW"
   },
   "outputs": [],
   "source": [
    "best_observed_value = exact_obj.max().item()\n",
    "best_observed_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibI-21seCe6U"
   },
   "source": [
    "We wrap all of the previous code into a function to be used freely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QX6Y4KY4ChtU"
   },
   "outputs": [],
   "source": [
    "def generate_initial_data(n=10):\n",
    "  train_x = torch.rand(n, 1, dtype=torch.double)\n",
    "  exact_obj = target_function(train_x).unsqueeze(-1)\n",
    "  best_observed_value = exact_obj.max().item()\n",
    "  return train_x, exact_obj, best_observed_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joClmvvSCz5C"
   },
   "outputs": [],
   "source": [
    "generate_initial_data(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8merVh3DEZM"
   },
   "source": [
    "Let us now invoke this function to start the BO iteration and set the bounds of the 1-D $f(x) : x \\in [0,10]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqXQD_GxDGxS"
   },
   "outputs": [],
   "source": [
    "init_x, init_y, best_init_y = generate_initial_data(20)\n",
    "bounds = torch.tensor([[-2.], [10.]]) #bounds for 2D: torch.tensor([[0., 1.], [10.,2.]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Feti3NQ6DlKN"
   },
   "source": [
    "We set which model and which likelihood will we use. In our case we will use a classic Gaussian process and compute its hyper-parameters using the exact marginal log likelihood (which can produce overfitting when points are reduced but well...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNz3ac16Djuf"
   },
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "\n",
    "single_model = SingleTaskGP(init_x, init_y)\n",
    "mll = ExactMarginalLogLikelihood(single_model.likelihood, single_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNgRjAMYEc75"
   },
   "source": [
    "Now that our model is declared, we fit the previous points with the Gaussian process setting its hyperparameters via Exact Marginal log likelihood of the points. The output shows the default covariance function used by the GP and its hyper-hyperparameters. It also shows the Gaussian likelihood used and the homoskedastic noise added to the Matern Kernel to capture the noise of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvruM2c7ElOR"
   },
   "outputs": [],
   "source": [
    "from botorch import fit_gpytorch_model\n",
    "fit_gpytorch_model(mll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8bMLqQyFJF2"
   },
   "source": [
    "Now we declare the acquisition function that is going to be computed using the predictive distribution of the previous Gaussian process in all the input space. We will use the expected improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7TUF0XhFOkj"
   },
   "outputs": [],
   "source": [
    "from botorch.acquisition.monte_carlo import qExpectedImprovement #use the noisy version if the problem has noise\n",
    "\n",
    "EI = qExpectedImprovement(model=single_model, best_f=best_init_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeBGVaMIFnjP"
   },
   "source": [
    "We will now optimize the acquisition function, all the hyper parameters here are a good heuristic default to try and find the global optima of the acquisition function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qvn-98cFnwy"
   },
   "outputs": [],
   "source": [
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "candidates, _ = optimize_acqf(acq_function=EI, bounds=bounds, q=1, num_restarts=200, raw_samples=512, options={\"batch_limit\": 5, \"maxiter\": 200})\n",
    "\n",
    "candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yQWkqbwGQoe"
   },
   "source": [
    "We now have all the code of an iteration so we just put it in a loop. To do so: We just wrap previous code into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZXLpbLSGQta"
   },
   "outputs": [],
   "source": [
    "def get_next_points(init_x, init_y, best_init_y, bounds, n_points=1):\n",
    "  single_model = SingleTaskGP(init_x, init_y)\n",
    "  mll = ExactMarginalLogLikelihood(single_model.likelihood, single_model)\n",
    "  fit_gpytorch_model(mll)\n",
    "\n",
    "  EI = qExpectedImprovement(model=single_model, best_f=best_init_y)\n",
    "  \n",
    "  candidates, _ = optimize_acqf(acq_function=EI, bounds=bounds, q=n_points, num_restarts=200, raw_samples=512, options={\"batch_limit\": 5, \"maxiter\": 200})\n",
    "\n",
    "  return candidates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG-WloyRHRox"
   },
   "source": [
    "We test the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLK5VJQ8HREn"
   },
   "outputs": [],
   "source": [
    "get_next_points(init_x, init_y, best_init_y, bounds, n_points=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lPBXD0ZHex0"
   },
   "source": [
    "Finally, we embed the previous code into the Bayesian optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQ1EGN1WHe-4"
   },
   "outputs": [],
   "source": [
    "n_iterations=2\n",
    "\n",
    "init_x, init_y, best_init_y = generate_initial_data(20)\n",
    "bounds = torch.tensor([[0.], [10.]])\n",
    "\n",
    "for i in range(n_iterations):\n",
    "  print(f\"Number of iterations done: {i}\")\n",
    "  new_candidates = get_next_points(init_x, init_y, best_init_y, bounds, 1)\n",
    "  new_results = target_function(new_candidates).unsqueeze(-1)\n",
    "\n",
    "  print(f\"New candidates are: {new_candidates}\")\n",
    "  init_x = torch.cat([init_x, new_candidates])\n",
    "  init_y = torch.cat([init_y, new_results])\n",
    "\n",
    "  best_init_y = init_y.max().item()\n",
    "  print(f\"Best point performs this way: {best_init_y}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0VhjwcLJTIL"
   },
   "source": [
    "Get the best observed result of the optimization. We can see in the previous figure how the result is exactly the maximum. The optimization has been successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fubEczeuJVb6"
   },
   "outputs": [],
   "source": [
    "print(f\"Best observed result: {best_init_y}\")\n",
    "best_candidate = init_x[((init_y == best_init_y).nonzero(as_tuple=True)[0])][0][0]\n",
    "print(f\"Best location of observed result: {best_candidate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XS4zdkHyjGWX"
   },
   "outputs": [],
   "source": [
    "def print_objective_function(best_candidate, iteration):\n",
    "  x = np.linspace(-2., 10., 100)\n",
    "  x_new = x.reshape((100,-1))\n",
    "  z = target_function(x_new)\n",
    "\n",
    "  data = go.Scatter(x=x, y=z, line_color=\"#FE73FF\")\n",
    "\n",
    "  fig = go.Figure(data=data)\n",
    "  fig.update_layout(title=\"Objective function. Iteration \" + str(iteration), xaxis_title=\"input\", yaxis_title=\"output\")\n",
    "  fig.add_vline(x=best_candidate, line_width=3, line_color=\"red\")\n",
    "  fig.show()\n",
    "\n",
    "\n",
    "print_objective_function(best_candidate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2xb2ZF7uAFW"
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(-2., 10., steps=100)\n",
    "x_test = torch.tensor([x[0]]).unsqueeze(-1)\n",
    "EI = qExpectedImprovement(model=single_model, best_f=best_init_y)\n",
    "EI(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bINYQFghHpLv"
   },
   "source": [
    "We can also plot the acquisition function, with its maximum, which is the point suggested to be evaluated in the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKLPtRcDwl0_"
   },
   "outputs": [],
   "source": [
    "def compute_acquisition_function(single_model, best_init_y, l_bound=-2., h_bound=10., resolution=1000):\n",
    "  linspace = torch.linspace(l_bound, h_bound, steps=resolution)\n",
    "  x_test = torch.tensor([linspace[0]]).unsqueeze(-1)\n",
    "  EI = qExpectedImprovement(model=single_model, best_f=best_init_y)\n",
    "  result = []\n",
    "  for x in linspace:\n",
    "    x_test = torch.tensor([x]).unsqueeze(-1)\n",
    "    result.append(EI(x_test))\n",
    "  return torch.tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "714LAje5xPXm"
   },
   "outputs": [],
   "source": [
    "def print_acquisition_function(acq_fun, iteration, l_bound=-2., h_bound=10., resolution=1000, suggested=None):\n",
    "  x = torch.linspace(l_bound, h_bound, steps=resolution).detach().numpy()\n",
    "  x_new = x.reshape((resolution,-1))\n",
    "  z = acq_fun\n",
    "  max_acq_fun = x[((acq_fun == acq_fun.max().item()).nonzero(as_tuple=True)[0])]\n",
    "  data = go.Scatter(x=x, y=z, line_color=\"yellow\")\n",
    "\n",
    "  fig = go.Figure(data=data)\n",
    "  fig.update_layout(title=\"Expected Improvement acquisition function. Iteration \" + str(iteration), xaxis_title=\"input\", yaxis_title=\"output\")\n",
    "  if(suggested==None):\n",
    "    fig.add_vline(x=max_acq_fun, line_width=3, line_color=\"red\")\n",
    "  else:\n",
    "    fig.add_vline(x=float(suggested[0][0]), line_width=3, line_color=\"red\")\n",
    "  fig.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U453GBQ3uALD"
   },
   "outputs": [],
   "source": [
    "acq_fun = compute_acquisition_function(single_model, best_init_y)\n",
    "print_acquisition_function(acq_fun, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_MimbgPHyXD"
   },
   "source": [
    "We can as well plot the GP predictive mean and standard deviation, its predictive distribution, for all the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPoMt0UPILAB"
   },
   "outputs": [],
   "source": [
    "def compute_predictive_distribution(single_model, best_init_y, l_bound=-2., h_bound=10., resolution=1000):\n",
    "  linspace = torch.linspace(l_bound, h_bound, steps=resolution)\n",
    "  x_test = torch.tensor([linspace[0]]).unsqueeze(-1)\n",
    "  result = []\n",
    "  variances = []\n",
    "  for x in linspace:\n",
    "    x_test = torch.tensor([x]).unsqueeze(-1)\n",
    "    result.append(single_model.posterior(x_test).mean)\n",
    "    variances.append(single_model.posterior(x_test).variance)\n",
    "  return torch.tensor(result), torch.tensor(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwnp9gtaIQ-4"
   },
   "outputs": [],
   "source": [
    "def print_predictive_mean(predictive_mean, predictive_variance, iteration, l_bound=-2., h_bound=10., resolution=1000, suggested=None, old_obs=[], old_values=[]):\n",
    "  x = torch.linspace(l_bound, h_bound, steps=resolution).detach().numpy()\n",
    "  x_new = x.reshape((resolution,-1))\n",
    "  z = predictive_mean\n",
    "  max_predictive_mean = x[((predictive_mean == predictive_mean.max().item()).nonzero(as_tuple=True)[0])]\n",
    "\n",
    "  fig = go.Figure()\n",
    "\n",
    "  fig.add_trace(go.Scatter(x=x, y= predictive_mean + np.sqrt(predictive_variance),\n",
    "                                     mode='lines',\n",
    "                                     line=dict(color=\"#19D3F3\",width =0.1),\n",
    "                                     name='upper bound'))\n",
    "  fig.add_trace(go.Scatter(x=x, y= predictive_mean,\n",
    "                         mode='lines',\n",
    "                         line=dict(color=\"blue\"),\n",
    "                         fill='tonexty',\n",
    "                         name='predictive mean'))\n",
    "  fig.add_trace(go.Scatter(x=x, y= predictive_mean - np.sqrt(predictive_variance),\n",
    "                         mode='lines',\n",
    "                         line=dict(color=\"blue\", width =0.1),\n",
    "                         fill='tonexty',\n",
    "                         name='lower bound'))\n",
    "  \n",
    "  \n",
    "  \n",
    "  fig.update_layout(title=\"GP Predictive distribution. Iteration \" + str(iteration), xaxis_title=\"input\", yaxis_title=\"output\", showlegend=False)\n",
    "\n",
    "  if(suggested==None):\n",
    "    fig.add_vline(x=max_predictive_mean, line_width=3, line_color=\"red\")\n",
    "  else:\n",
    "    fig.add_vline(x=float(suggested[0][0]), line_width=3, line_color=\"red\")  \n",
    "\n",
    "  if(len(old_obs)>0):\n",
    "    fig.add_trace(go.Scatter(x=old_obs, y=old_values, mode = 'markers', marker_color=\"black\", marker_size=10))\n",
    "\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SejE404H6em"
   },
   "outputs": [],
   "source": [
    "predictive_mean, predictive_variance = compute_predictive_distribution(single_model, best_init_y)\n",
    "print_predictive_mean(predictive_mean, predictive_variance, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3as3CZOVQUCi"
   },
   "source": [
    "We can embed all this logic into the BO loop to have visualizations of the objective function, GP predictive distribution and acquisition function in every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozDHlSM-SmDW"
   },
   "outputs": [],
   "source": [
    "def visualize_functions(single_model, best_init_y, best_candidate, candidate_acq_fun, iteration, previous_observations, previous_values):\n",
    "  predictive_mean, predictive_variance = compute_predictive_distribution(single_model, best_init_y)\n",
    "  print_predictive_mean(predictive_mean, predictive_variance, iteration, suggested=candidate_acq_fun, old_obs=previous_observations, old_values=previous_values)\n",
    "  acq_fun = compute_acquisition_function(single_model, best_init_y)\n",
    "  print_acquisition_function(acq_fun, iteration, suggested=candidate_acq_fun)\n",
    "  print_objective_function(best_candidate, iteration)\n",
    "\n",
    "def get_next_points_and_visualize(init_x, init_y, best_init_y, bounds, iteration, previous_observations, previous_values, n_points=1):\n",
    "  single_model = SingleTaskGP(init_x, init_y)\n",
    "  mll = ExactMarginalLogLikelihood(single_model.likelihood, single_model)\n",
    "  fit_gpytorch_model(mll)\n",
    "\n",
    "  EI = qExpectedImprovement(model=single_model, best_f=best_init_y)\n",
    "  \n",
    "  candidates, _ = optimize_acqf(acq_function=EI, bounds=bounds, q=n_points, num_restarts=200, raw_samples=512, options={\"batch_limit\": 5, \"maxiter\": 200})\n",
    "  best_candidate = init_x[((init_y == best_init_y).nonzero(as_tuple=True)[0])][0][0]\n",
    "\n",
    "  visualize_functions(single_model, best_init_y, best_candidate, candidates, iteration, previous_observations, previous_values)\n",
    "\n",
    "  return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xM0l_oxWR6dA"
   },
   "outputs": [],
   "source": [
    "n_iterations=10\n",
    "\n",
    "init_x, init_y, best_init_y = generate_initial_data(20)\n",
    "bounds = torch.tensor([[0.], [10.]])\n",
    "\n",
    "candidates=[]\n",
    "results=[]\n",
    "for i in range(n_iterations):\n",
    "  print(f\"Number of iterations done: {i}\")\n",
    "  new_candidates = get_next_points_and_visualize(init_x, init_y, best_init_y, bounds, i, candidates, results, 1)\n",
    "  new_results = target_function(new_candidates).unsqueeze(-1)\n",
    "\n",
    "  print(f\"New candidates are: {new_candidates}\")\n",
    "  init_x = torch.cat([init_x, new_candidates])\n",
    "  init_y = torch.cat([init_y, new_results])\n",
    "\n",
    "  best_init_y = init_y.max().item()\n",
    "  print(f\"Best point performs this way: {best_init_y}\")\n",
    "  candidates.append(float(new_candidates[0][0]))\n",
    "  results.append(float(new_results[0][0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
